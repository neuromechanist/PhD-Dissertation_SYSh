\documentclass{UCF_ETD}
% \usepackage{times} % obsolete font package
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{cite}
\usepackage{color,soul}
\newcommand{\huang}{\textcolor{red}}
\newcommand{\seyed}{\textcolor{blue}}
\newcommand{\ignore}[1]{}
\newcommand{\tss}[1]{\textsuperscript{#1}}
\renewcommand{\ul}{}
%%%%%%
% This template is set up for all paragraphs to be flush against the left margin 
% with extra space between paragraphs. If you prefer to indent all paragraphs, 
% please read the .cls file to see which lines should be uncommented to implement indentation.
%%%%%%%%%



\title{\uppercase{Corticomuscular adaptation to mechanical perturbations in a seated locomotor task}} %Must be typed in all caps.
\author{\uppercase{Seyed Yahya Shirazi}} % typed in all caps



\prevdegreeii{B.Sc. AmirKabir University of Technology (Tehran Polytechnic), 2011}
\prevdegreei{M.Sc. AmirKabir University of Technology (Tehran Polytechnic), 2014}
% commands available for 
% \prevdegreei{ }
% \prevdegreeii{ }
% \prevdegreeiii{ }

\thesisname{dissertation}
% \thesisname prints out document type. Replace bracket text with dissertation for Ph.D students

\degreename{Doctor of Philosophy in Mechanical Engineering}
% type out degree name here.

\departmentsname{Mechanical and Aerospace Engineering}
% replace with department name if applicable.  Otherwise, do not include.

%\schoolname{Kenneth G. Dixon School of Accounting}
% replace with school name if applicable.  Otherwise, do not include.

\collegename{Engineering and Computer Science}
% replace with college name

\termname{Spring}
% replace with semester

\termyear{2021}
% replace with year. Term year is also used to generate copyright year.

\advisorname{Helen J. Huang}
% replace with Major Professor if applicable.  Otherwise, do not include.


\begin{document}

\frontmatter
% applies roman numerals as page numbers

\maketitle
% prints out school info as named above

\copyrightpage{~Seyed Yahya Shirazi}
% includes copyright symbol. Term year is automatically inserted before the author name.  Replace the author name with your own, but keep the tilde in place. 

\begin{abstract}
Seated locomotor tasks such as cycling or recumbent stepping improve walking performance during rehabilitation. Cortical control during walking is most pronounced when the person is perturbed. But, the electrocortical dynamics during perturbed seated tasks has not been studied in detail. The primary purpose of this research was to quantify cortical and muscular responses to mechanical perturbations during recumbent stepping. We also aimed to quantify possible differences between young and older adults' responses to perturbed stepping. Before 
% abstract files can be added here.  I recommend using \input over \include
\end{abstract}

\dedication{Dedicated to my love, Maryam.}
% creates vertically and horizontally centered dedication page.  If larger than a paragraph, remove the \vspace*fil commands from the dedication section in the class file.

\begin{acknowledgments}
The acknowledgments page is optional. If you choose to use it, it should appear after the Abstract, but before the Table of Contents.
\end{acknowledgments}

\tableofcontents

\listoffigures

\listoftables

\mainmatter
% restarts page numbering with arabic numbers

\chapter{INTRODUCTION} 
% chapter headings must be typed in all caps as any \MakeUppercase command does not transfer to the PDF file through hyperref.
Chapter and major headings should be typed in all caps.  Note that Chapter titles should be formatted and positioned exactly the same as frontmatter and other major headings. However, chapters with subtitles may be stacked, single-spaced, rather than appear on one line.
The Introduction presents an overview of the thesis or dissertation material to be discussed. For sample theses and dissertations, including sample Introductions from your discipline, visit the University Writing Centerâ€™s Graduate Gateway, located at http://www.uwc.ucf.edu. Please be aware that UWC links are for content samples only, not format samples.



\section{First-level Subheading}
First-level subheadings are centered, and occur in title case (upper/lower case letters). 
% Subheading formatting is set in the class file.  If you choose to use the alternative subheading formatting from the Thesis and Dissertation Manual or another style guideline, you will need to alter the subsection commands in the class style.

\subsection{Second-level Subheading}
Second-level Subheadings are usually centered in title case with no additional formatting. 

\subsubsection{Third-level Subheading}
Third-level subheadings are underlined and left-justified, still in title case. 

\paragraph{Fourth-level Subheading}
Fourth-level headings look like second-level headings, except that fourth-level headings are justified.

\subparagraph{Fifth-level Subheading}
The maximum number of subheadings you may use is five.  The fifth-level subheading is indented and underlined. 

\chapter{More Reliable EEG Electrode Digitizing Methods Can Reduce Source Estimation Uncertainty, But Current Methods Already Accurately Identify Brodmann Areas}
\section{Introduction}
Estimating active cortical sources using electroencephalography (EEG) is becoming widely adopted in multiple research areas as a non-invasive and mobile functional brain imaging modality  \citep{Tsolaki2017-nt,Bradley2016-wg,Landsness2011-mr,Nystrom2008-ex}. EEG is the recording of the electrical activity on the scalp and is appealing for studying cortical dynamics during movements and decision making due to the high temporal (i.e. millisecond) resolution of electrical signals. One of the challenges of using EEG is that the signal recorded in an EEG electrode is a mixture of electrical activity from multiple sources, which include the cortex, muscles, heart, eye, 60 Hz noise from power lines, and motion artifacts from cable sway and head movements \citep{Kline2015-mf,Symeonidou2018-ge}. To meaningfully correlate EEG analyses with brain function, the unwanted source content such as muscle activity, eye blinks, and motion artifacts need to be attenuated or separated from the cortical signal content. A multitude of tools such as independent component analysis, artifact rejection algorithms, and phantom heads have been developed to address the need to separate the source signals to extract the underlying cortical signal \citep{Delorme2012-re,Mullen2013-xv,Artoni2014-jy,Oliveira2016-hy,Nordin2018-aq}. Using high-density EEG and improving EEG post-processing techniques have also improved spatial resolution of source estimation to $\thicksim$ 1 cm in experimental studies \citep{Seeber2019-dn,Hedrich2017-of,Klamer2015-yp,Scarff2004-ll,Lantz2003-om,He1989-dw}.

Source estimation requires knowing the EEG signals and the locations of the EEG electrodes to estimate the locations of the cortical sources that produced the EEG signals measured on the scalp. An intuitive assumption of source estimation is that precise placement of the EEG electrodes on the scalp is essential for accurate estimation of source locations \citep{Keil2014-mv}. Computational studies reported shifts of 0.5 cm to 1.2 cm in estimated source locations as a result of 0.5 cm (or 5\textdegree) error in the electrode digitization \citep{Kavanagk1978-zc,Khosla1999-bz,Wang2001-fp,Beltrachini2011-je,Akalin_Acar2013-rv}. For EEG studies conducted inside a magnetic resonance imaging (MRI) device, the electrode locations with respect to the cortex can be captured and processed \ul{with less than 0.3 cm position error}, which results in near perfect alignment of identified brain areas \citep{Marino2016-pu,Scarff2004-ll}. However, for studies that do not involve MRI, the electrode locations should be ``digitized'', i.e. recorded digitally via a three-dimensional (3D) position recording method \citep{Koessler2007-qg}. These digitized locations can then be coupled with either a subject-specific or an averaged template of the brain structure obtained from MRI or other imaging techniques to perform EEG source estimation.  

Just one decade ago in the mid-2000's, the main digitizing technologies available were based on ultrasound and electromagnetism, which were expensive, time consuming, and needed trained operators \citep{Koessler2007-qg,Rodriguez-Calvache2018-qi}. An ultrasound digitizing system uses differences in ultrasound-wave travel times from emitters on \ul{the person's face and} a digitizing wand to an array of receivers to estimate the 3D location of the tip of the digitizing wand \ul{with respect to the face emitters}. An electromagnetic system tracks the locations of receivers \ul{placed on the person's head and }on a wand in an emitted electromagnetic field to estimate the position of the tip of the wand \ul{with respect to the head receivers}. The environment must be clear of magnetic objects when using an electromagnetic digitizing system, otherwise the electrode locations will be warped  \citep{Engels2013-gm,Cline2018-qo}. 

Recent efforts have focused on developing technologies to make digitization more accessible and convenient, mainly by incorporating image-based technologies \citep{Koessler2010-fm,Baysal2010-zi}. For example, using photogrammetry and motion capture methods for digitization can provide accurate electrode locations in a short period of time \citep{Clausner2017-hv,Reis2015-lt}. Photogrammetry involves using cameras to take a series of color images at different view angles. These images can then be analyzed to identify the locations of specific points in the 3D space \citep{Clausner2017-hv,Russell2005-hg}. Motion capture typically uses multiple infrared cameras around the capture volume to take simultaneous images to identify the locations of reflective or emitting markers. If markers are placed directly on the EEG electrodes, a motion capture system could conveniently record the position of all of the electrodes at once \citep{Reis2015-lt,Engels2013-gm}. Motion capture could also be used to record the position of the tip of a probe, a rigid body with multiple markers, to digitize 3D locations of \ul{the electrodes with respect to the reflective face markers}. Several recent commercial digitizing systems use simple motion capture approaches to digitize EEG electrode locations with or without a probe \citep{Song2018-qz,Cline2018-qo,Brainsight2019-tn,xensor2019-al}.

Another option for digitizing EEG electrodes that has also gained much interest recently are 3D scanners. A common approach for 3D scanning is detecting the infrared or visible reflections of projected light patterns with a camera to estimate the shape of an object \citep{Chen1987-py}. The 3D scanned shapes can then be plotted in a software program such as MATLAB, and the locations of specific points on the 3D scanned shape can be determined. Recently, common EEG analysis toolboxes such as EEGLAB \citep{Delorme2004-yy} and FieldTrip \citep{Oostenveld2010-ss} support using 3D scanners to digitize the electrode locations. Studies suggest that 3D scanners can improve digitization accuracy and significantly reduce digitization time \citep{Taberna2019-zv}. Using other camera-based systems such as time-of-flight scanners and virtual reality headsets were also reported to provide comparable digitization reliabilities as the ultrasound or electromagnetic digitizing methods, while reducing the time spent for digitizing the EEG electrodes \citep{Cline2018-qo,Vema_Krishna_Murthy2014-qk,Zhang2014-jh}.

The purposes of this study were 1) to compare the reliability and validity of five digitizing methods and 2) to quantify the relationship between digitization reliability and source estimation uncertainty.\ignore{ We only accounted for the digitization variability of having multiple operators digitize EEG electrode locations with different digitizing methods, and tried to minimize other sources of variability.} We determined source estimation uncertainty using spatial metrics and Brodmann areas.
We hypothesized that digitizing methods with less reliability would increase uncertainty in the estimates of the electrocortical source locations. For our analyses, we assumed that all other contributors to source estimation uncertainty such as variability of head-meshes and assumptions of electrical conductivity values were constant.

\section{Methods}
We fitted a mannequin head with a 128-channel EEG cap (ActiveTwo EEG system, BioSemi B.V., Amsterdam, the Netherlands, Figure \ref{fig:m1}A) and used this mannequin head setup to record multiple digitizations of the locations of the EEG electrodes and fiducials, i.e. right preauricular, left preauricular, and nasion \ul{\citep{Klem1999-ai}}. To prevent the cap from moving from digitization to digitization, we taped the cap to the mannequin head  (Figure \ref{fig:m1}A). To help ensure that the fiducials were digitized at the same locations for every digitizing method, we marked the fiducials with small 4-mm markers on the mannequin head and with small o-rings on the cap (Figure \ref{fig:m1}A). 

\subsection{Digitizing methods}
We compared five methods for digitization: ultrasound, structured-light 3D scanning, infrared 3D scanning, motion capture with a digitizing probe, and motion capture with reflective markers. \ul{We calibrated each digitizing device only once and completed collecting data for each digitizing in a single session (see Table S1 in the supplement for the calibration results). We also kept the position of the mannequin head, mannequin head orientation, start and endpoint of digitizing, lighting, and temperature constant to avoid introducing additional sources of error to our data collection and analysis.}

For each method, \ul{four different} members of the laboratory digitized the mannequin head five times \ul{(one person performed the digitization twice)}. All of the operators had prior experience in digitizing and were asked to follow each method's specific guidelines. We imported the digitization data to MATLAB (version 9.4, R2018a, Mathworks, Natick, MA) and performed all analyses in MATLAB.

\subsubsection{Ultrasound}
We used a Zebris positioning system with ElGuide software version 1.6 (Zebris Medical GmBH, T\"ubingen, Germany, Figure \ref{fig:m1}B) to digitize the electrodes with an ultrasound method. Following the Zebris manual, we placed 3 ultrasound emitters on the face of the mannequin head, placed the receiver module in front of the mannequin head, and used the digitizing wand to record the electrode locations. We calibrated the system using the ElGuide calibration procedure. We marked the fiducials repeatedly until we obtained fiducials with a digitized 3D location of nasion that was $<$ 2mm with respect to the midline and with preauriculars that had a difference of $<$ 5mm in the anterior/posterior and top/bottom directions. Operators followed the interactive ElGuide template to digitize each electrode location. This process involved fully placing the wand tip into the electrode wells and ensuring that the receivers were able to see all emitters at the time of recording electrode locations, so that the estimated position of the wand tip was stable. 

\subsubsection{Structured-light 3D scan}
We used an Einscan Pro+ (Shining 3D Tech. Co. Ltd., Hangzhou, China, Figure \ref{fig:m1}C) to digitize the electrodes with a structured-light 3D scanner. This scanner estimates the shape of an object from reflections of the projected visible lights. We calibrated the Einscan Pro+ one time with the Einscan's calibration board and followed the software's step-by-step instructions. We used the scanner's hand-held rapid mode with high details and allowed the scanner to track both texture and markers during the scanning process. Each operator scanned the mannequin head until the scan included the cap, fiducials, and the face. We then applied the watertight model option to the scan and exported the model as a {\tt PLY} file to continue the digitization process in MATLAB.

After acquiring the 3D scan, the 3D head model needed to be imported into a software program, where the operator manually marked the EEG electrode locations on the 3D scanned head model. We followed the FieldTrip toolbox documentation for digitization using 3D scanners \citep{ft_scan_tut} and created a MATLAB script file for importing and digitizing 3D models of the mannequin head. The operator first marked the fiducials on the mannequin head model in MATLAB to build up the head coordinate system. Then, the operator marked the locations of the electrodes on the screen in each section of the cap in alphanumerical order (A, B, C, D, and the fiducials, total: 131 locations, Figure \ref{fig:m1}A). The operators referred to a physical EEG cap for guidance to help mark the locations in the expected order because these scans were not in color and the letter labels of the electrodes were not visible on the 3D model.

\subsubsection{Infrared 3D scan}
We used the Structure sensor (model ST01, Occipital Inc., San Francisco, CA) integrated with an Apple\tss{\textregistered} iPad (10-inch Pro) to digitize the electrodes with an infrared dot-projection 3D scanner (Figure \ref{fig:m1}D). This scanner shares similar working principles as a structured-light scanner but uses infrared light projection to estimate the shape of objects. We calibrated the sensor in daylight and office light according to the manual. We scanned the head using the high color and mesh resolutions. When the mannequin head was completely in the sensor's field of view, the operator started scanning. The Structure sensor interface gives the operator visual feedback to help the operator obtain a complete high-quality scan. We visually inspected that the scanned model matched the mannequin and then exported the model to the MATLAB environment. We used the FieldTrip toolbox to import and digitize the 3D mannequin head scans following the same procedure described for the structured-light 3D scan digitization. 

\subsubsection{Motion capture probe}
We used a digitizing probe and a 22-camera motion capture system (OptiTrack, Corvallis, OR) to digitize the electrodes. The probe is a solid rigid body with four fixed reflective markers (Figure \ref{fig:m1}E). We placed three reflective makers on the face of the mannequin to account for possible movements of the head during data collection. Each operator digitized the fiducials and each section of the cap (A, B, C, D, Figure \ref{fig:m1}A) in separate takes. We placed double o-rings seven millimeters away from the probe tip to ensure consistent placement of the tip inside the electrode wells (Figure \ref{fig:m1}E). The tracking error of the motion capture system was less than 0.4 millimeters. 

\subsubsection{Motion capture}
We used the motion capture system to record the locations of 35 3D printed reflective markers that resembled a 4-millimeter reflective marker on top of a BioSemi active pin electrode (Figure \ref{fig:m1}F). We did not use actual BioSemi electrodes, which have wires that could prevent the cameras from seeing the markers. We placed 27 EEG electrode shaped markers to approximate the international 10-20 EEG cap layout and placed an additional eight EEG electrode shaped markers randomly \ul{on} the cap to add asymmetry to improve tracking of the markers. We recorded 2-second takes of the positions of the 35 markers, three markers on the fiducials, and three face markers. Before transforming the locations to the head coordinate system, we identified and canceled movements of the head during data collection using the three face markers.

\subsection{Transformation to head coordinates}
We developed a dedicated pipeline to convert the digitized electrode locations for each digitizing method to a format that could be imported to the common toolboxes for EEG analyses. Because EEGLAB and FieldTrip can easily read Zebris ElGuide's output file (an {\tt SFP} file), we created {\tt SFP} files for all digitizations.

The head coordinate system in ElGuide defines the X-axis as the vector connecting the left preauricular to the right preauricular and the origin as the projection of the naison to the X-axis. Therefore, the Y-axis is the vector from the origin to the naison, and the Z-axis is the cross product of the X and Y unit vectors, which starts from the origin.

\subsection{Digitization reliability and validity}
Variations in the digitized electrode locations could originate from random errors and systematic bias. The effects of random errors can be quantified as variability. Reliability is also inversely related to variability. Systematic bias can be quantified as the difference between measured locations and the ground truth locations. Validity is also inversely related to systematic bias.

\subsubsection{Digitization reliability}
\label{subsec:digitRel}
To assess the effects of random errors, we quantified digitization variability. We averaged the five digitized locations for each electrode to find the centroid. We then calculated the average Euclidean distances of the five digitized points to the centroid for each electrode and averaged those distances for all of the electrodes to quantify within-method variability. We identified and excluded outliers, single measurements that were beyond five standard deviations of the average variability for a digitizing method \ul{(1 out of 655 measurements for ultrasound, 4 out of 655 measurements for motion capture probe and 2 out of 190 measurements for motion capture)}. If there were outliers, we recalculated the average digitization reliability with the updated dataset. Throughout the paper, we use ``variability'' to refer to ``within-method variability.'' Because reliability is inversely related to the variability, the most reliable method has the least variability. 

\subsubsection{Digitization validity}
To quantify the systematic bias of a digitizing method, we calculated the average Euclidean distance between the centroid for a digitizing method and the ground-truth centroid for the same electrode. We used the electrode centroids from the most reliable digitizing method as the ground-truth \citep{Dalal2014-nk}. Then, we averaged the Euclidean distances for the 128 electrodes to obtain the magnitude of the systematic bias for each digitizing method. Because validity is inversely related to the systematic bias, the most valid method has the least systematic bias. 

\subsection{Source estimation uncertainty}
\label{subsec:soEst}
To generalize the possible effects of digitization reliability, we synthesized 500 sets of electrode locations with a Gaussian distribution using the variability average and standard deviation calculated for each digitizing method in \ref{subsec:digitRel}. We excluded the motion capture method from the source estimation uncertainty analyses because we only recorded the locations of 35 EEG electrode shaped reflective markers instead of all 128 EEG electrode locations. 
We used a single representative 128-channel EEG dataset from a separate study for the source estimation analyses. We applied the Adaptive Mixture Independent Component Analysis (AMICA) to decompose EEG signals into independent components (ICs) \citep{Palmer2007-sv}, which has been reported to represent dipolar activities of different brain and non-brain sources \citep{Delorme2012-re}. 

We used EEGLAB's DIPFIT toolbox version 2.3 to estimate a dipole equivalent for each IC and applied DIPFIT 500 times for each digitizing method. Each DIPFIT iteration used one of the 500 sets of synthesized electrode locations, the Montreal Neurological Institute (MNI) head model \citep{Evans1993-nx}, and the ICs from the AMICA. The MNI head model is an averaged structural head model from 305 participants and provides 1mm $\times$ 1mm $\times$ 1mm resolution. To convert the mannequin head to be compatible with the MNI model, we warped the electrode locations to the MNI model using only the fiducials to preserve individual characteristics of the mannequin head. We used the dipoles produced with the electrode location centroids \ul{from} the digitizing method with the highest reliability and identified the dipoles that described $>$ 85\% of the IC signal variance. We also excluded any dipole that was estimated to be outside of the brain volume for any of the DIPFIT results (500/method $\times$ five methods = 2500 DIPFIT results). In the end, 23 ICs remained.  

\subsubsection{Spatial uncertainty}
We fitted an enclosing ellipsoid with the minimum volume to each IC's cluster of 500 dipoles \citep{Moshtagh2005-em} and quantified spatial uncertainty in terms of the volume and width of the ellipsoid. A larger ellipsoid volume indicated that a single dipole could reside within a larger volume, and thus, had greater volumetric uncertainty. A larger ellipsoid width indicated that a single dipole could have a larger shift in location. We calculated the ellipsoid's width as the maximum distance that the IC's dipoles could have from one another. We averaged the volumes and widths of all 23 ICs to quantify the spatial uncertainty for each digitizing method. 
    
\subsubsection{Brodmann area accuracy}    
To identify Brodmann areas, we used a modified version of the {\tt \texttt{eeg\_tal\_lookup}} function from EEGLAB's Measure Projection Toolbox (MPT). This function looks for the anatomic structures and Brodmann areas in a 10-mm vicinity of each dipole and assigns the dipole to the Brodmann area with the highest posterior probability \citep{Bigdely-Shamlo2013-jv,Lancaster2000-aj}. \ul{We identified the ``ground-truth" Brodmann areas from the dipoles estimated using the centroid electrode locations of the most reliable digitizing method.} Then, we calculated Brodmann area accuracy as the percentage of the other 500 Brodmann area assignments that matched the ``ground-truth" Brodmann area. 

We also analyzed Brodmann area accuracy using a template of electrode locations based on the MNI head model \citep{Oostenveld2001-vg}. Because the BioSemi 128-electrode cap is not based on the 10-10 electrode map, \ul{instead of using the 10-10 electrode locations, we warped the BioSemi electrode locations to reside on the outer surface of the MNI head model.} We then compared the Brodmann area identified from the template to the ``ground-truth" Brodmann area. \ul{Since there is only one template for the Biosemi 128-electrode location on the MNI head model and the locations are fixed}, we could not calculate a percentage of assignments; thus, the template's Brodmann area for each IC was either a hit or miss. However, we did calculate and compare the distance between the template's dipole to the ``ground truth" dipole. \ul{We also compared} the distance between each digitizing method's dipoles to the ``ground truth" dipole. These distances indicated whether the dipoles \ul{estimated using each digitization method} were near the ``ground truth" dipole. 

\subsection{Statistical analysis}
We used a one-way repeated measures analysis of variance (rANOVA) to compare the reliability and validity of the digitizing methods, the spatial uncertainty of the estimated dipoles, and the Brodmann area accuracy. For significant rANOVA's, we performed Tukey-Kramer's post-hoc analysis to determine which comparisons were significant. We also performed a one-sided Student t-test to identify if the Brodmann area accuracy of each digitizing method was different from the template. The level of significance for all statistics was $\alpha$ = 0.05. \ul{For rANOVA, we reported degrees of freedom (DF), Fisher's F-test result and the probability value (p-value). We used p-values to report post-hoc and Student t-test results.} 

Additionally, we fit a polynomial, using a step-wise linear model (MATLAB {\tt stepwiselm} function), to describe spatial uncertainty as a function of digitization variability. We forced the y-intercept of the first-order polynomials and the y-intercept and y'-intercept of the higher-order polynomials to be zero. We set the y-intercepts to be zero for two reasons: 1) when we used the exact same electrode locations and performed DIPFIT 100 times, the maximum distance between source locations was on the order of 10\tss{-4} cm, and 2) the fit should not model the uncertainty values $<$ 0 for positive digitization variability values. The step-wise linear model started with a zero order model and only added a higher-order polynomial term when necessary. The criterion for adding a higher-order polynomial term to the model was a statistically significant decrease of the sum of the squared error between the data points and the predicted values.

\section{Results}

The variability \ul{results} for the five digitizing methods were visibly different, and electrodes located at the back of the head tended to have greater variability (Figure \ref{fig:r1}). The variability for the ultrasound method was generally largest compared to the other methods and could be as large as $\thicksim$1.5 cm for electrodes at the back of the head. The variability for all electrodes digitized with the motion capture method was small, being no greater than 0.001 cm. 

There was a range of reliabilities among the digitizing methods (Figure \ref{fig:r2}A). The motion capture digitizing method had the smallest variability of 0.001 $\pm$ 0.0003 cm (mean $\pm$ standard deviation) and hence, the greatest digitization reliability. The motion capture probe was the next most reliable method with an average variability of 0.147 $\pm$ 0.03 cm, followed by the infrared 3D scan (0.24 $\pm$ 0.05 cm), the structured-light scan (0.50 $\pm$ 0.09 cm), and the ultrasound digitization (0.86 $\pm$ 0.3 cm). The variability for the digitizing methods were significantly different (rANOVA \ul{DF=4, F=1121,} p$<$0.001), and the variability for each digitizing method was significantly different from all other digitizing methods (post-hoc Tukey-Kramer, p's $<$0.001). 

The systematic biases, thus validities, of the digitizing methods were significantly different (rANOVA \ul{DF=2, F=143.1,} p$<$0.01, Figure \ref{fig:r2}B). The digitization validity of the structured-light 3D scan was the worst of the digitizing methods with a systematic bias of 0.63 $\pm$ 0.18 cm that was significantly larger than the other digitizing methods (post-hoc Tukey-Kramer, p's $<$0.001). The digitization validity of the ultrasound and the infrared 3D scans were similar, with systematic biases of 0.43 $\pm$ 0.18 cm and 0.41 $\pm$ 0.13 cm, respectively.

Within a given digitizing method, dipoles generally showed similar spatial uncertainty while different digitizing methods generally showed differences in spatial uncertainty (Figure \ref{fig:r4}). Ellipsoid sizes for the motion capture probe, infrared 3D scan, structured-light 3D scan, and ultrasound digitization increased in order from the smallest to the largest, respectively. The enclosing ellipsoids of adjacent ICs also overlapped when the ellipsoid size was large, on the order of 1 cm\tss{3}, such as for the ultrasound method. 

Ellipsoid volumes increased significantly with increasing digitization variability among the digitizing methods and had a cubic relationship (r\tss{2} = 1.00, Figure \ref{fig:r5}A). The motion capture probe and infrared 3D scan had the smallest uncertainty volumes (mean $\pm$ standard error) 0.007 $\pm$ 0.0007 cm\tss{3} \& 0.029 $\pm$ 0.0027 cm\tss{3}, respectively, whereas ultrasound had the largest uncertainty volume (1.37 $\pm$ 0.13 cm\tss{3}). Structured-light 3D scan had an average uncertainty volume of 0.21 $\pm$ 0.014 cm\tss{3}. The volumes of the enclosing ellipsoids showed a significant between-group difference (rANOVA, \ul{DF=3, F=114.4,} p$<$0.001), and all uncertainty volume combinations of paired digitizing methods were significantly different (Tukey-Kramer post-hoc, p's$<$0.001). 

Ellipsoid widths also increased significantly with increasing digitization variability among the digitizing methods but had a linear relationship where the ellipsoid width was twice the size of the digitization variability (r\tss{2} = 1.00, Figure \ref{fig:r5}B). The average ellipsoid width was the smallest for the motion capture probe, (mean $\pm$ standard error) 0.34 $\pm$ 0.018 cm. The average ellipsoid widths for the two 3D scans were 0.53 $\pm$ 0.028 cm for the infrared 3D scan and 1.09 $\pm$ 0.051 cm for the structured-light 3D scan. The largest average ellipsoid width was for the ultrasound digitization, 1.90 $\pm$ 0.081 cm. The rANOVA for the widths of the enclosing ellipsoids showed a significant between-group difference (\ul{DF=3, F=434.8}, p$<$0.001) and all combinations of paired digitizing methods had significantly different uncertainty widths (Tukey-Kramer post-hoc p's$<$0.001).

The Brodmann area accuracy among the digitizing methods could be extremely consistent within some ICs and could also be drastically different for other ICs (Figure \ref{fig:r6} and in Supplement Figure S1). In general, the digitizing method with the highest reliability also had the highest Brodmann area accuracy within a given IC. For some ICs, all digitizing methods had $>$ 98\% Brodmann area accuracy. For other ICs, the Brodmann area accuracy decreased as reliability decreased. The most drastic example for this dataset was BA18 in Figure \ref{fig:r6}, where the Brodmann area accuracy was 86\% with the motion capture probe method but dropped to 26\% with the ultrasound method.  

The Brodmann area accuracy for the digitizing methods and the template were significantly different (Figure \ref{fig:r7}). The motion capture probe had the highest Brodmann area accuracy, 93\% $\pm$ 16 (mean $\pm$ standard deviation). The remaining digitizing methods in order of decreasing Brodmann area accuracy were the infrared 3D scan (91\% $\pm$ 19\%), the structured light 3D scan (87\% $\pm$ 23\%), and the ultrasound digitization (79\% $\pm$ 25\%). The rANOVA for the Brodmann area accuracy showed a significant between-group difference (\ul{DF=4, F=306.4,} p$<$0.001). Post-hoc Tukey-Kramer analysis showed significant pair-wise difference between all groups except the motion capture probe and infrared 3D scan. Using the MNI electrode template decreased the Brodmann area accuracy to 53\% and was significantly different compared to any of the digitizing methods (p's$<$0.001). The average distance of the dipoles of each digitizing method to the ``ground-truth" dipole was less than 0.4 cm while the average distance of the template dipoles to the ``ground-truth" dipole was $\thicksim$ 1.4 cm. 

\section{Discussion}

We found that there was a range of reliability and validity values among the digitizing methods. \ul{We also observed} that less reliable digitizing methods translated to greater uncertainty in source estimation and poorer Brodmann area accuracy, assuming all other contributors to source estimation uncertainty were constant. Of the five digitizing methods (ultrasound, structured-light 3D scan, infrared 3D scan, motion capture probe, and motion capture), the most reliable digitizing method was the motion capture while ultrasound was the least reliable. The structured-light digitizing method had the greatest systematic bias and was thus the least valid method. We had hypothesized that less reliable digitizing methods would lead to greater source estimation uncertainty. In support of our hypothesis, digitizing methods with decreased reliability resulted in increased spatial uncertainty of the dipole locations and decreased Brodmann area accuracy. Surprisingly, any digitizing method led to an average Brodmann area accuracy of $>$80\%. Using a template of electrode locations decreased Brodmann area accuracy to 53\%. Overall, these results indicate that electrode digitization is crucial for accurate Brodmann area identification using source estimation and that more reliable digitizing methods are beneficial if the functional resolution for interpreting source estimation is more specific than Brodmann areas.

To help summarize the advantages of the different digitization systems, we created a table comparing the digitization reliability, dipole uncertainty, speed, affordability, and ease-of-use score, which are different factors that could influence which digitization a laboratory might choose to use (Table \ref{tab:t1}). We estimated the digitizing speed as how much time each digitization required. The fastest digitizing method that required manual electrode marking was the motion capture probe method, which took 5 minutes to mark each electrode and 5 minutes to calibrate the system. The least expensive system was the infrared 3D scanner, which is likely to become even less expensive as cameras on smartphones become more advanced and could soon be used to obtain an accurate 3D scan for digitizing EEG electrodes. We also surveyed the operators to score each digitization on a scale of 1-5, with 1 being easy to use. While performing the actual 3D scan was perceived as being easy, marking the electrodes in MATLAB was not an easy task. The operators indicated that the motion capture was the easiest and that ultrasound was the most difficult method to use. To create a final ranking, we averaged the rankings for each factor (digitization reliability, dipole uncertainty, speed, affordability, and ease-of-use) to obtain a method score. Based on the method score, the best digitizing method was the motion capture. The next best method was tied between the motion capture probe and infrared 3D scan. The fourth best digitizing method was the structured-light 3D scan, and the worst digitizing method was the ultrasound method, which ranked poorly for all factors.

Our results suggest that the motion capture method currently \ul{provides the most reliable electrode digitization}. \ul{The average variability of the motion capture digitization was less than the mean calibration error reported by the motion capture system (0.001 versus $<$0.04 cm respectively). This difference might be because of the different natures of the two variabilities. The digitization variability is defined for a seated subject (or mannequin) and multiple sub-second snapshots of the static electrodes placed on the cap. However, the mean calibration error is defined for a set of moving markers in a much larger volume across several minutes of a calibration period. Using the same position for mannequin placement and lack of head movement may have also contributed to the small digitization variability using motion capture} In a previous study, Reis and Lochmann developed an active-electrode motion capture approach for an EEG system with 30 electrodes and reported small deviation of the digitized locations from the ground truth locations \citep{Reis2015-lt}. 
In addition to having sub-millimeter variability, the motion capture method only required 1-2 seconds to digitize, assuming that the markers were already placed on the EEG electrodes. However, tracking 64+ markers on an EEG cap may be challenging for most motion capture systems.\ignore{ In this study, we only tracked 35 markers on the EEG cap and may have been able to track more than 35 markers with our 22-camera motion capture system.} Determining the maximum number of EEG electrodes that could be digitized using a motion capture approach could be beneficial and pursued in future work. Laboratories that already have a motion capture system and do not need to digitize more than 64 EEG electrodes could conveniently use the motion capture method, which would provide a cost-effective, fast, and easy digitizing process.For laboratories that need to digitize 64+ electrodes and have a motion capture system already, the motion capture probe digitizing method would be the recommended option.

\ul{Our results support recent efforts to use 3D scanners as a reliable and cost-effective method to digitize EEG electrodes \citep{Taberna2019-zv,Chen2019-sc, Homolle2019-pd}.} Both the structured-light and infrared 3D scanning methods were more reliable than digitizing with the ultrasound method. Furthermore, our reliability results for the two 3D scanners align well with a recent study that showed that an infrared 3D scan could automatically digitize electrode locations on three different EEG caps and achieve good reliability after additional post-processing \citep{Taberna2019-zv}. Of the two 3D scanners we tested, the less expensive infrared 3D scanner was more reliable, had higher validity, and resulted in less dipole uncertainty, compared to the structured-light 3D scanner. Even though the structured-light 3D scanner provides more details from the mannequin head and cap, those details did not seem to be important for improving digitization reliability or validity. Additionally, the highly detailed structured-light 3D scans created large files and resulted in sluggish refresh rates that made \ul{using FieldTrip toolbox to rotate and manipulate the 3D scans difficult}. The infrared 3D scan, unlike the structured-light 3D scan, was in color, which was helpful for the operators to identify the EEG electrodes more easily on the computer screen. In the future, artificial intelligence approaches may be able to fully automate the digitizing process and use the additional topographic details from high resolution 3D scans. A continuous image-based digitizing method such as using a regular video recorded using a typical smartphone could also potentially be developed to digitize EEG electrode locations. 

Compared to simulation studies, our experimental results demonstrated that source estimation uncertainty increased steeply with increasing EEG electrode variability. We showed that a digitizing method with an average variability of 1 cm could lead to a shift of a single dipole by more than 2 cm, which is $>$ 20\% of the head radius. There is just one simulation study that we know of that also showed a 2-fold increase in source uncertainty for every unit of digitization variability \citep{Akalin_Acar2013-rv}. In that study, digitization variabilities were created using systematic rotations applied to every electrode location. The majority of the simulation studies however, suggest that source uncertainty could only be as large as the digitization variability \citep{Khosla1999-bz,Van_Hoey2000-jt,Wang2001-fp,Beltrachini2011-je}. In one of the mathematical studies, the theoretical lower bound of source estimation uncertainty was 0.1cm for 0.5cm shifts in EEG electrode location \citep{Beltrachini2011-je}, which is 10x smaller than our experimental results. While simulation studies can be insightful, results should also be cross-validated with a conventional source estimation method (e.g. DIPFIT, LORETA or minimum norm) to determine whether simulation results are indicative of real-world source estimation uncertainty.

Because researchers often use Brodmann areas to describe the function of a source, we translated our results to be in terms of Brodmann area accuracy, which led to a few surprising revelations. The main revelation was that despite the range of digitization reliabilities, any of the digitizing methods we tested produced an average Brodmann area accuracy $>$ 80\%. As long as sources are only discussed according to Brodmann areas or larger cortical spatial regions, any current digitizing method can be used. The second revelation was that using the template electrode locations, instead of digitizing the electrodes, significantly decreased Brodmann area accuracy from $>$ 80\% to $\thicksim$ 50\%, which may be due to a $\thicksim$ 1.5cm shift in dipoles locations (Figure \ref{fig:r7}). This shift may occur because the template removes information related to individual's head shape. The third revelation was that for several sources, the same Brodmann area was almost always identified, regardless of the digitizing method used (left column in Figure \ref{fig:r6}). For other sources, less reliable digitizing methods led to more potential Brodmann area assignments (right column in Figure \ref{fig:r6}), but those different Brodmann areas may be functionally similar. Most likely, the proximity of a source to the boundary of a Brodmann area as well as the size of the Brodmann area contribute to Brodmann area accuracy. Ultimately, the accuracy of source estimation will depend on the target volumes of cortical regions of interest.

\ul{This study does not account for all of the possible sources of errors contributing to digitizing EEG electrodes or source estimation. We placed markers on the fiducials to control for the digitization error of the fiducials, but in practice, marking the fiducials while the subject wears the cap can be challenging. Mismarking a fiducial can significantly shift every dipole location by 2 times the distance of the fiducial mismarking \citep{Shirazi2019-ke}. We also used a mannequin to control for the head movements and relative cap movements to the head. In reality, participants may move their head and the cap may slightly change position during digitization or data collection that would affect the location of the EEG electrodes with respect to the head. Further, we only calibrated our digitizing devices once for multiple data collections. Nevertheless, in a real laboratory setup, device calibration might be required before each instance of data collection. We, however, included digitization by multiple experienced operators to acknowledge that in a research laboratory different members might complete the digitization for different participants. Overall, our results suggest that as long as all sources of digitization error do not create variability $>$ 1 cm, Brodmann area accuracy would be $>$ 80\%. Using the same electrical head model and source localization approach helped us to only quantify the effects of digitization variability on source estimation uncertainty. In reality, the EEG signal noise, number and distribution of EEG electrodes, electrical properties of the head model, head model shape and mesh accuracy, and solving approach are among the other potential contributors to source estimation uncertainty \citep{Akalin_Acar2013-rv,Akalin_Acar2016-jr,Mahjoory2017-jv,Dalal2014-nk,Song2015-fv,Beltrachini2019-lf}.}

Limitations of this study were that we tested a subset of all digitizing methods, \ul{used a mannequin head, and not an actual human head for the digitization}, and did not perform source estimation using other common algorithms. Even though we did not test many of the marketed digitizing systems, we replicated and tested the fundamental methods used by most of the marketed digitizing systems. One widely used EEG electrode digitizing method we did not test is an electromagnetic digitizing method (e.g. Polhemus Patriot or Fastrack system). Another study using similar digitization reliability analyses reported an average variability of 0.76cm for an electromagnetic digitization system \citep{Clausner2017-hv}, which is slightly better than the ultrasound digitizing method, with a variability of 0.86 $\pm$ 0.3cm. \ul{Collecting digitization data from an actual participant might have helped in having a better distribution of the sources inside the brain volume, but we decided to use a mannequin to better control for head movements, relative cap movements and other environmental factors. Here, we used the EEG data only to provide a platform to understand the relationship between the digitization variability and source uncertainty, and locations of the sources do not have any neurological implications}. Last, we did not use other different source estimation algorithms such as LORETA or beam-forming. Studies indicate that commonly used source estimation algorithms generally identify the similar source locations \citep{Mahjoory2017-jv,Bradley2016-sk,Song2015-fv}, which suggests that the choice of the source estimation algorithm used would probably not significantly alter our results. 

Future efforts to improve source estimation, so that sources can be interpreted in terms of cortical spatial regions smaller than Brodmann areas, will involve more than just developing more reliable, convenient, and cost-effective digitizing methods to help reduce source estimation uncertainty. Even if a perfect digitizing method could be developed, there would still be uncertainty in source estimation as result of other factors such as improper head-model meshes and inaccurate electrical conductivity values \citep{Beltrachini2019-lf, Akalin_Acar2016-jr}, which were assumed to have a constant contribution to the source estimation uncertainty in our analyses. Obtaining and using as much subject specific information, such as subject-specific MRI scans in addition to digitizing EEG electrode locations, should improve source estimation. EEGLAB's Neuroelectromagnetic Forward Head Modeling Toolbox (NFT) could be used to warp the MNI head model to the digitized electrode locations to retain the individual's head shape but is computationally expensive \citep{Acar2010-ye}. Using subject-specific MRIs instead of the MNI head model is also limited to groups with access to an MRI at an affordable cost per scan.

\section{Conclusion}

In summary, there was a range of digitization reliabilities among the five digitizing methods tested (ultrasound, structured-light 3D scanning, infrared 3D scanning, motion capture with a digitizing probe, and motion capture with reflective markers), and less reliable digitization resulted in greater spatial uncertainty in source estimation and poorer Brodmann area accuracy. We found that the motion capture digitizing method was the most reliable while the ultrasound method was the least reliable. Interestingly, Brodmann area accuracy for a source only dropped from $\thicksim$ 90\% to $\thicksim$ 80\%, when using the most and least reliable digitizing methods, respectively. If source locations will be discussed in terms of Brodmann areas, any of the digitizing methods tested could provide accurate Brodmann area identification. Using a template of EEG electrode locations, however, decreased the Brodmann area accuracy to $\thicksim$ 50\%, suggesting that digitizing EEG electrode locations for source estimation results in more accurate Brodmann area identifications. Even though digitizing EEG electrodes is just one of the factors that affects source estimation, developing more reliable and accessible digitizing methods can help reduce source estimation uncertainty and may allow sources to be interpreted in terms of cortical regions more specific than Brodmann areas in the future. 

\section*{Conflict of Interest Statement}
The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

\section*{Author Contributions}
HJH proposed the problem. SYSH and HJH designed the experiment, conducted data collections, and analyzed the data. SYSH and HJH wrote and edited the manuscript.

\section*{Funding}
This work was partially supported by the National Institute on Aging of the National Institutes of Health, under award number R01AG054621. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.

\section*{Acknowledgments}
This manuscript has been released as a Pre-Print at BioRxiv \citep{Shirazi2019-hf}.\ul{ MATLAB functions and dependencies for the motion capture and 3D scan digitizing methods are available on GitHub at {\tt \href{https://github.com/neuromechanist/eLocs}{github.com/neuromechanist/eLocs}}}.

\ignore{\section*{Data Availability Statement}
MATLAB functions and scripts for motion capture, motion capture probe and 3D scan digitizations are publicly available at \url{https://github.com/neuromechanist/easy_digitization}. Brodmann area accuracy functions with a sample data structure for select ICs are available at \url{https://github.com/neuromechanist/baa}.}

\bibliographystyle{frontiersinSCNS_ENG_HUMS}
\bibliography{digitization.bib}

\section*{Figure captions}

\begin{figure}[h!]
    \centering
    \includegraphics{img/method1-r2.eps}
    \caption{The mannequin head used for digitization and the five digitizing methods tested. \textbf{A:} The mannequin head fit with the 128-electrode EEG cap used for all of the digitizing recordings. \ul{The right and left preauriculars were marked by o-rings and nasion was marked with a reflective marker}. The color-coded map of the cap shows the different electrode strips and the order of digitization from A to D. \textbf{B:} The ultrasound digitizing system and an operator placing the tip of the wand in the electrode well on the cap. \ul{Two of the total five ultrasound emitters on the face and wand, as well as the data acquisition (DAQ) box and the receiver module are also indicated.} \textbf{C:} The structured-light 3D scanner and an operator manually marking the locations of individual electrodes of the scanned model in MATLAB. \textbf{D:} The infrared 3D scanner and an operator manually marking the locations of individual electrodes of the colored 3D scan in MATLAB. \textbf{E:} The motion capture digitizing probe with a close-up view of the o-rings placed 7 millimeters away from the tip. The probe \ul{has a similar role} to the wand in the ultrasound system. \textbf{F:} The EEG cap with 35 3D-printed EEG electrode shaped reflective markers, 3 face markers, and 3 fiducial markers used for the motion capture digitization. \ul{We placed reflective markers on top of the preauricular o-rings to be able to capture fiducial locations.} The electrode map depicts the approximate locations of the digitized electrodes and grounds.}
    \label{fig:m1}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=1.0]{img/result1.eps}
    \caption{Visualization of the digitization reliability. Colored and scaled dots show the electrode location within-method variability for all 128 electrodes for the five digitizing methods. Ultrasound had the greatest variability and was the least reliable. The electrodes at the back of the head also tended to have the greatest variability. The motion capture method had the least variability and was the most reliable. The color bar and scale for the radii of the dots illustrate the magnitude of variability.}
    \label{fig:r1}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=1.0]{img/result2.eps}
    \caption{\textbf{A:} Reliabilities, quantified as the average variability, were significantly different for the five digitizing methods. The reliability of each digitizing method was significantly different from all other methods (\textbf{*} = Tukey-Kramer p's $<$0.001 for all pair-wise comparisons).
    \textbf{B:} Validity, quantified as the average systematic bias showed that the structured-light 3D scan had the largest systematic bias compared to ultrasound and the infrared 3D scan. The motion capture probe method was assumed to be the ground truth and thus has no systematic bias and is not shown. \textbf{*} = Tukey-Kramer p's $<$0.001. Error bars are the standard deviation. infrared = infrared 3D scan. str.-light = structured-light 3D scan. m.+probe = motion capture probe. mocap = motion capture.}
    \label{fig:r2}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics{img/result4.eps}
    \caption{An example depiction of the synthesized electrode locations with a Gaussian distribution using the same averaged variability and standard deviation as the structured-light 3D scans, and the enclosing ellipsoids of the 500 dipoles for each independent component (IC) and digitizing method. Black dots = centroids of the electrode locations. Light gray dots = first 150 out of 500 synthesized electrode locations. Each color represents a different IC (23 ICs total). A close-up view of the ellipsoid fit for an Anterior Cingulate IC based on the reliability of the ultrasound digitizing method.}
    \label{fig:r4}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics{img/result5.eps}
    \caption{The relationships between digitization variability and dipole spatial uncertainty. \textbf{A:} Digitization variability and ellipsoid volume had a cubic relationship with an r\tss{2} of 1.00. \textbf{B:} Digitization variability and ellipsoid width had a linear relationship with an r\tss{2} of 1.00. Error bars are the standard error. \textbf{*} = Tukey-Kramer p's $<$0.001 for all pair-wise comparisons. m.+probe = motion capture probe. infrared = infrared 3D scan. str.-light = structured-light 3D scan.}
    \label{fig:r5}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics{img/result6.eps}
    \caption{Brodmann area (BA) accuracy for a subset of ICs. The dipole depicts the ``ground truth" dipole produced from the most reliable digitizing method, the motion capture probe method. The pie charts show the distribution of the Brodmann area assignments compared to the ``ground truth" Brodmann area (shown in bold). ICs in the left column had consistent Brodmann area assignments regardless of digitizing method while the ICs in the right column had more varied Brodmann area assignments for the different digitizing methods. In general, less reliable digitizing methods led to less consistent Brodmann area assignments.}
    \label{fig:r6}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics{img/result7.eps}
    \caption{Brodmann area accuracy plotted versus the average dipole distance from the ``ground truth" dipole when using different digitizing methods and the MNI template. Because larger distances between the dipoles and the ``ground truth" likely would decrease Brodmann area accuracy, we plotted the methods on the x-axis at the method's averaged dipole distance from the ``ground truth" dipole. The box-whisker plot contains the Brodmann area accuracy averages for the 23 ICs. The Brodmann area accuracy average for an IC was the average of the percentage of the 500 iterations when the Brodmann area identified matched the ``ground truth" Brodmann area for that IC. For the template, 53\% of the Brodmann areas assigned for the 23 ICs using the template matched the ``ground truth" Brodmann area. The Brodmann area accuracy was significantly different among the digitizing methods, except between the motion capture probe and infrared 3D scan (\textbf{*} Tukey-Kramer p's $<$0.001). The template's Brodmann area accuracy was significantly different than all digitizing methods (\textbf{\#} Student's t-test p's $<$0.001). m.+probe = motion capture probe. infrared = infrared 3D scan. str.-light = structured-light 3D scan.}
    \label{fig:r7}
\end{figure}


\begin{table}[h!]
\centering
\caption{Rankings for each digitizing method based on factors related to performance, cost, and convenience. \# is the rank of each method among all five methods and for the specified factor. The digitization reliability values and dipole uncertainty scalar width values were taken from our results. Speed was the approximate time a digitizing method required to obtain the file of electrode locations. The ease-of-use score was the average score operators provided in a survey with a score of 5 being the most difficult and 1 being the easiest method to do. The method score is the average rank of all factors for a given method and was defined as $score=\sum{\#}/N$. Dipole uncertainty was not available for motion capture digitization. Mocap = motion capture. Str.-Light 3D = structured-light 3D scan. \textbf{*} The probe price is for the OptiTrack digitizing probe. \textbf{**} motion capture cost was for an eight-camera system (Optitrack Flex13, \$8000) and the Optitrack Motive software (\$3000).}

\begin{footnotesize}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multirowthead{2}{method} & \multicolumn{2}{c|}{\thead{digitization reliability}} & \multicolumn{2}{c|}{\thead{dipole uncertainty}} & \multicolumn{2}{c|}{speed} & \multicolumn{2}{c|}{affordability} & \multirowthead{2}{ease-of-use \\ (1 is easiest)} & \multirowthead{2}{method score\\(lower is better)} \\ 

\cline{2-9} & \gape{mean Â± SD (cm)} & \# & mean Â± SD (cm) & \# & time (min) & \# & cost (USD) & \# &  &  \\ \hline

\Gape[6pt]{ultrasound} & 0.86 Â± 0.30 & 5 & 1.90 Â± 0.39 & 4 & 30 & 5 & 15k & 5 & 4.2 & 4.6 \\ \hline

\cellgape{\makecell{infrared \\3D scan}} & 0.24 Â± 0.05 & 3 & 0.53 Â± 0.136 & 2 & \Gape{\makecell{20 (10 for scan\\ + 10 for marking \\in software)}} & 3 & 1k & 1 & 2.5 & 2.3 \\ \hline

\cellgape{\makecell{str.-light \\3D scan}} & 0.50 Â± 0.09 & 4 & 1.09 Â± 0.24 & 3 & \Gape{\makecell{25 (10 for scan\\ + 15 for marking \\in software)}} & 4 & 5k & 2 & 3.4 & 3.3 \\ \hline


\cellgape{\makecell{mocap \\probe}} & 0.15 Â± 0.03 & 2 & 0.34 Â± 0.08 & 1 & \makecell{10 (5 for digitizing \\+ 5 for calibration)} & 2 & \Gape{\makecell{1k\tss{*} (probe)\\ 12k\tss{**}(+mocap)}} & 4 & 2 & 2.2 \\ \hline

\Gape{mocap} & 0.001 Â± 0.0003 & 1 & N/A & - & \Gape{\makecell{5.1 (0.1 for digitizing \\+ 5 for calibration)}} & 1 & \Gape{\makecell{11k\tss{**}}} & 3 & 1 & 1.5 \\ \hline
\end{tabular}
\end{footnotesize}
\label{tab:t1}
\end{table}

\chapter{Influence of Mismarking Fiducial Locations on EEG Source Estimation}
\section{Introduction}

Digitizing electrode locations is an essential step for setting up a head model to estimate cortical and subcortical sources from magneto-/electro-encephalography (M/EEG) signals \cite{Koessler2007-qg}. The digitizing process involves recording three-dimensional positions of the M/EEG electrodes in a global coordinate system and transforming the locations from the global coordinates to the head coordinate system. This transformation requires that the two coordinate systems share at least three anatomical landmarks (i.e. fiducials). The fiducials are typically the left preauricular, right preauricular, and nasion \cite{Koessler2007-qg,Fuchs2007-dd}.

After digitizing the 3D locations of the fiducials and electrodes, these locations are warped to a head model or vice versa \cite{Akalin_Acar2013-rv}. For studies that involve concurrent tomographic imaging such as magnetic resonance imaging (MRI), digitization, transformation to the head coordinate system, and warping to the head model can be made simultaneously \cite{Marino2016-pu}, but for other studies, digitized locations must be manually coregistered to construct the head model \cite{Koessler2007-qg}. Therefore, digitizing can significantly affect the ability to achieve a realistic head model and estimations of source locations \cite{Akalin_Acar2013-rv}.

To our knowledge, only a couple of studies examined the effects of digitizing errors on source estimation, and outcomes of these studies do not seem consistent. Beltarchini and collegues \cite{Beltrachini2011-je} suggested that effects of electrode mislocations are negligible on the estimated source locations, while Dalal et al. \cite{Dalal2014-nk} showed that quality of the output signal degrades significantly with higher uncertainties in the electrode digitization. We did not find any published study that examined the possible effects of mismarking fiducial locations on source estimation.

The purpose of this study was to analyze changes in the estimated source location as a result of shifting the fiducial locations to simulate mismarking of the fiducials. We hypothesized that changes in the locations of the fiducials would have a significant effect on the dipole fitting process and source localization.

\section{Methods}

We fitted a mannequin head with a 128-electrode BioSemi (BioSemi B.V., Amsterdam, the Netherlands) cap and digitized the locations of the electrodes and fiducials (left preauricular, LPA; right preauricular, RPA; and nasion, Nz) using an OptiTrack 22-camera motion capture system and a digitizing probe (NaturalPoint Inc., Corvallis, OR). The average (Â±SD) reliability of this digitization method was <1.50 Â± 0.3 mm for digitizing the mannequin head five times.

To define the head coordinate system, we assumed the LPA and RPA were on the X-axis, and Nz was on the Y-axis (Figure \ref{fig:coor}A). The origin of the head coordinate system was located at the projection of Nz to the X-axis. The Z-axis was defined as the cross product of the X and Y unit vectors and began from the origin. We transformed the digitized electrode locations of the mannequin head to the head coordinate system and used this set of electrodes as the baseline.

\begin{figure}[bt]
      \centering
      \includegraphics[scale=1.0]{img/fig0.eps}
      \caption{\textbf{A.} The mannequin head used for digitization with a representation of the head coordinate system. Right preauricualr (RPA) and nasion (Nz) are labeled in the picture. \textbf{B.} The baseline dipole locations of the 23 independent components (ICs) from a separate study but estimated with the mannequin head digitization rather than the individual subject digitizations using ultrasound. These ICs were used to analyze the influence of the systematic fiducial shifts on the dipole locations.}
      \label{fig:coor}
\end{figure}

To create multiple sets of electrode locations with various fiducial locations, we shifted one fiducial at a time, in 1 mm increments, up to Â±20 mm in the Y and then the Z directions for the preauriculars, RPA and LPA, and in the X and then the Z directions for the nasion, Nz. This process resulted in 12 fiducial shifts per 1 mm increment (3 fiducials $\times$ four directions), totaling 240 sets of electrode locations (12 fiducial shifts per 1 mm increment $\times$ 20 fiducial shift increments).

Digitization post-processing and the subsequent analyses throughout the study were performed using MATLAB version 9.4 (R2018a, Mathworks Inc., Natick, MA) and EEGLAB \cite{Delorme2004-yy} version 14.1.2. We used just the fiducial locations to warp the locations of the electrodes and fiducials to the Montreal Neurological Institute's template head model.

\subsection{Source Estimation and Dipole Fitting}
We used a single representative EEG dataset and weightings of a single Adaptive Mixture Independent Component Analysis (AMICA) from a separate study to perform dipole fitting using the multiple sets of electrode locations with the systematic shifts of the fiducial locations. This representative EEG dataset and ICA had 89 independent components, ICs. We used the DIPFIT toolbox version 2.3 to fit dipoles to the ICs. We visually inspected for dipoles with residual variances <15\% that stayed inside the brain area across every fiducial shifts, which resulted in total 23 remaining ICs (Figure \ref{fig:coor}B). We analyzed the influence of the fiducial shifts on all twenty-three ICs but picked three to illustrate dipole location alterations in detail: 1) the anterior cingulate, 2) the primary somatosensory cortex, and 3) the premotor cortex. Previous studies have shown that these three areas are active in locomotion and error monitoring \cite{Luu2017-ph,Peterson2018-ht}.

\subsection{Dipole Uncertainty Analysis}
We defined the baseline set of dipoles as the dipoles produced using the baseline locations for the fiducials and electrodes (i.e. no shifts). Each set of electrode locations based on a shifted fiducial produced a new set of dipoles. There were 240 sets of electrode locations resulting in 240 sets of dipoles around the baseline dipole. We considered that the spread or size of the cluster of dipoles was representative of the uncertainty related to the resulting dipole locations.

We quantified dipole uncertainty as the volume of a set of tetrahedrons formed from connecting the 12 dipoles created by shifting every fiducial in 1-mm step in every direction (three fiducials $\times$ 4 direction/fiducial). We identified the outside boundary of the 12-dipole clusters and created the tetrahedrons using MATLAB's {\tt convexHull} function.

We also calculated the maximum dipole cluster width between the dipoles with equidistant fiducial shifts (i.e. the same 12 dipoles used for creating tetrahedrons). Since the tetrahedral volumes did not have similar shapes at each fiducial shift, we formed equivalent rectangular cubes with volumes equal to the tetrahedral volumes and the width equal to the maximum cluster width. Hence, for the equivalent rectangular cubes, $V = D \times E^2$, where $V$ is the tetrahedral volume, which is also the equivalent cube's volume, $D$ is the maximum cluster width that forms the cube's width, and $E^2$ is the cross-sectional area of the cube.

We used step-wise polynomial fits to model the relationship between the uncertainty volume and the fiducial shift distance, and the maximum dipole cluster width and the fiducial distance.

\subsection{Random Fiducial Mismarkings}
Creating random combinations of fiducial shifts is another approach to analyze the effects of fiducial mismarkings. We generated 100 electrode location datasets for every 1-mm increment of the random fiducial mismarking combinations, producing 2000 datasets (100 datasets/increment $\times$ 20 increments = total 2000 datasets). Each one-hundred mismarkings resided on a circular path with a fixed radius (1$\leq$ r $\leq$20 mm) away from the fiducial baseline locations. We ran DIPFIT using each dataset and compared the results with the outcomes of the systematic fiducial shifts.

\section{Results}

Shifting LPA, Nz, and RPA in different increments and directions resulted in dipole locations that had curvilinear paths in different planes. Each shift direction created changes in similar directions for the dipoles of the three ICs but with different magnitudes (Figure \ref{fig:sl}).

\begin{figure*}[t!]
      \centering
      \includegraphics[width=\linewidth]{img/fig1.eps}
      \caption{Fiducial mislocations and their corresponding estimated dipoles for \textbf{A.} Left preauricular (LPA), \textbf{B.} Nasion (Nz) and \textbf{C.} Right preauricular (RPA) for three independent components (ICs). Dipoles are located at the anterior cingulate (A.Cing.), the primary somatosensory cortex (Somat.) and at the premotor cortex (Premot.). Lighter colors show positive direction for the fiducial shifts. For each fiducial, resultant dipoles are plotted in sagittal, frontal and top views.}
      \label{fig:sl}
\end{figure*}

The uncertainty volume increased quadratically as a function of the magnitude of the fiducial shifts (r\tss{2} = 0.920, Figure \ref{fig:unc}A). The uncertainty volume was $\thicksim$0.06 cm\tss{3} for fiducial shifts up to 0.5 cm for every IC. For fiducial shifts up to 1.3 cm, all three ICs showed similar increases in uncertainty volumes to ~0.5 cm\tss{3}. With fiducial shifts >1.3 cm, the uncertainty volume of all ICs, including the three ICs of interest, began to separate from one another. At a 2 cm shift in fiducials, the average uncertainty volume was >2 cm\tss{3}.

\begin{figure}[h!]
      \centering
      \includegraphics[scale=1.0]{img/fig2.eps}
      \caption{\textbf{A.} Relationship between the uncertainty volume and fiducial shifts. ICs in Figure \ref{fig:sl} are drawn in color: anterior cingulate (ant. cingulate), somatosensory cortex (somatosens.) and premotor cortex (premotor). Tetrahedrons represent dipole uncertainty at the anterior cingulate. Pink cubes has the same volume as the tetrahedral volumes, with the same width as the maximum cluster width (D). The green dashed line quadratically models the uncertainty volume as a function of the fiducial shift.
      \textbf{B.} Maximum cluster width (D) of the dipoles estimated from the equidistant fiducial shifts. The green dashed line relates the maximum cluster width to the fiducial shift.}
      \label{fig:unc}
\end{figure}

The maximum dipole cluster width for an IC had a linear relationship with the fiducial shifts (r\tss{2} = 0.79, Figure \ref{fig:unc}B). The average maximum cluster width exceeded 1 cm for shifts greater than 0.5 cm and was $\thicksim$4 cm for fiducial shifts of 2 cm. Some of the cluster widths of different ICs started to deviate from the linear fit for the fiducial shifts >0.5 cm, although, we did not observe similar trend for the uncertainty volumes. The dipole located in the primary somatosensory cortex had larger maximum distances than the ICs in the anterior cingulate and premotor cortex for fiducial shifts greater than 1.3 cm.

Comparing results of the random fiducial mismarking combinations and the tetrahedral volumes from the systematic fiducial shifts, we found that 1) For each 1-mm increment, no random combination of the fiducial shifts (out of 100) could cancel out the effects of the shifts and result in a dipole that could make the uncertainty volume or cluster width smaller, and 2) >95\% of the dipole estimations with random fiducial mismarking combinations at each 1-mm increment were in a close proximity of the corresponding tetrahedral surface (within $\thicksim$20\% of the maximum cluster width).

\section{Discussion and Conclusion}
This study revealed the relationship of fiducial mismarkings during electrode digitization on the subsequent uncertainty of dipole location estimation. We found that shifts of a single fiducial location up to 0.5 cm resulted in an uncertainty volume <0.06 cm\tss{3} and a maximum distance <1 cm. When fiducial shifts were greater than 1.3 cm, dipole location uncertainty increased to >1 cm\tss{3} and the maximum distance increased to >2 cm.

One interesting finding was that the largest maximum distances, among the three ICs of interest,  occurred in the primary somatosensory cortex, which is an area frequently discussed in the EEG studies related to walking \cite{Peterson2018-ht,Luu2017-ph}. A previous study found that tangential sources near the boundary of the cortex were more sensitive to electrode location errors, which could explain the larger maximum distances for the dipole at the primary somatosensory cortex compared to a dipole deeper within the cortex such as the anterior cingulate \cite{Beltrachini2011-je}.

Another interesting finding was that the linear fiducial shifts mapped to curvilinear dipole paths in different planes, which allowed the use of superposition to estimate dipole uncertainties created from fiducial mismarking combinations. Fiducial mismarking combinations are less likely to cancel each other, since the mismarking directions map to dipole paths in different planes. Fiducial mismarking combinations also created dipole spreads close to the uncertainty volumes that the systematic fiducial shifts had predicted. 

Dipole cluster width was more sensitive to the fiducial shifts compared to volumetric uncertainty. Dipole cluster width had a steep linear relation with the fiducial shifts and mismarking the fiducials could change the location of a dipole as much as twice the fiducial mismarking shift. A recent study found that the reliability of a widely-used electromagnetic electrode digitizing system was $\thicksim$0.8 cm \cite{Clausner2017-hv}. Hence, even with perfect markings of the fiducials, there will still be up to 1.5 cm (17\% of the head radius) uncertainty for the estimated dipole locations, just as a result of the reliability of the digitizing device.

Limitations of this study were that we did not examine every combination of the fiducial mismarkings and that we only co-registered the fiducials with the MNI head model for warping the electrode locations to the head model. While examining every combination of fiducial mismarkings was not practical, an advantage of analyzing random combinations of the fiducial mismarkings with the same distance from the baseline was that this approach could be used to estimate the mismarking effects for multiple digitizing systems if the digitizing reliability is known. While we could have co-registered more electrodes to the MNI head model, this would lose the individual characteristics of the digitized head. Alternatively, EEGLAB's NFT toolbox enables warping of the MNI head model to all of the digitized electrode locations \cite{Acar2010-ye}, but coupling NFT with 240 incremental electrode-location datasets was beyond our computational capacity. 

Based on our results, we recommend using a digitizing system with measurement errors less than 0.5 cm and marking the fiducials within 0.5 cm of the actual fiducial to avoid errors greater than 1.5 cm in dipole location. Future work will compare the reliability of different digitizing systems to determine which digitizing systems have measurement errors less than the recommended 0.5 cm. While digitizing the actual locations of the EEG electrodes should provide greater dipole specificity, this study showed that small fiducial mismarkings could result in large dipole location uncertainty. To reduce dipole location uncertainty, care should be taken to minimize the cumulative potential errors from the user mismarking fiducial locations during the digitization process and the measurement errors from the digitization system.

\bibliography{refs}
\bibliographystyle{ieeetr}
% \begingroup
% % \renewcommand{\section}[2]{}%
% \renewcommand{\chapter}[2]{}% for other classes

% \endgroup



% If you choose to number headings and/or subheadings (e.g. 3.1, 3.1.1), you will need to change the secnumdepth to reflect the degree of numbering you wish to implement throughout your document.  

% This template is currently set to 0 so that chapter headings are numbered, but subheadings are unnumbered.

% Unless the nature of your ETD requires unique chapter headings such as creative MFA projects, set the secnumdepth to a minimum of 0 to insert chapter numbering.  

% To number subheadings, change the number to 5 to include all possible subheadings. 

% Creative works using chapter headings for a novel or other creative work will need to change the secnumdepth to -1 to remove the chapter name from the heading.

\chapter{FINDINGS}
Chapter Four, also called ``Results'' or ``Data Analysis,'' usually provides detailed findings of the research.  This chapter is where tables and figures most often appear, so make sure formatting is consistent.

\section{Sample Table}
The following sample table is an example of acceptable table formatting. Descriptive titles appear above tables and may appear either on one line or stacked and single-spaced. The table itself may also be single-spaced as necessary. If at all possible, try to keep tables and/or figures all on one page. If necessary, start the table or figure on a new page, even if this means leaving blank space on the preceding page. If you must split a table over multiple pages, repeat the table headings and continue. It is not necessary to repeat the table title.

% If tables or figures are being inserted in the middle of a sentence rather than at the end of the paragraph, change the place signifier to [h!] to override LaTeX's placement.

\begin{table}[h]
\centering
\caption{Classroom Tallies}
\begin{tabular}{ |c|c|c|c|}
\hline
D & A & B & C\\
\hline
E &  3  & 4 & 7\\
\hline
F  &  5   & 8 & 9\\
\hline
\end{tabular}
\end{table}

\section{Sample Figure}
The following is a sample figure with acceptable figure formatting. For figures, be sure you format both the figure and the figure title consistently. This includes placement (centered or left-justified), spacing before and after, line spacing, point size and font.

\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{Picture1}
\caption{Green Sea Turtle}
\end{center}
\end{figure}

\chapter{CONCLUSION}
Chapter Five, also called ``Summary,'' ``Conclusion,'' or ``Recommendations,'' usually presents a conclusion to the research, offers recommendations to the problem investigated, or discusses implications for future studies.

\section{Bookmarks}
A few words about bookmarks. Frontmatter entries, like the Abstract, Acknowledgments and the Table of Contents should appear in the bookmarks â€“ but not in the Table of Contents. The TOC contains only pages that appear after the Table of Contents in the document, usually beginning with the List of Figures. So, bookmark and Table of Contents entries do vary.
However, bookmarks should include all major and chapter headings and at least first-level subheadings EXACTLY as they appear in the document (and the TOC). And readers should be able to link to pages within the ETD from all of the bookmarks, the TOC entries, as well as the Lists of Figures and Tables.
% all bookmarks are created through hyperref, so be sure that any additional packages are compatible.

\appendix

\chapter{TITLE OF APPENDIX}
\newpage
% You must include a \newpage command after each appendix.  And each appendix can be inserted as a chapter after the \appendix command.  

% This template is set to auto-letter multiple appendices.  

% If you change the secnumdepth to -1  and use multiple appendices, you must include the appendix name with the appendix title, such as APPENDIX A: TITLE.  If you have only one appendix, title it APPENDIX: TITLE.

% If you use chapter numbering and have only one appendix, you will need to comment out line 753 in the class file, containing the command \gdef\thechapter{\@Alph\c@chapter}}, and uncomment line 754 to define \gdef\thechapter{}} and remove the auto-lettering.


\noindent\labelitemi{~Begin appendix text on the page following the buffer page by using the newpage command.}\\
\labelitemi{~Continue Arabic pagination; do not restart page numbering with an appendix}\\
\labelitemi{~Use the same style and format for buffer page headings as you do for other body chapter headings.}\\
\labelitemi{~Letter, don't number, appendixes (e.g. APPENDIX A, APPENDIX B, etc.)}\\
\labelitemi{~If you have only one appendix, do not letter it at all}\\
\labelitemi{~Appendixes should follow the margin and other formatting requirements from the rest of the document}\\


\chapter{SECOND APPENDIX}
\newpage

Supplementary documentation.

\backmatter

\begin{thebibliography}{99}

\bibitem{Turkle95}
	Sherry Turkle,
	\emph{Life on the Screen}.
	Cambridge, MA: MIT Press,
	1995.

% this template does not include any packages for references.  It is compatible with natbib and other common reference packages, but you will need to add them to the document.
\end{thebibliography}

\end{document}